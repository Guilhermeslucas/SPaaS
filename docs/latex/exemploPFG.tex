% Exemplo de relatório técnico do IC
% Criado por P.J.de Rezende antes do Alvorecer da História.
% Modificado em 97-06-15 e 01-02-26 por J.Stolfi.
% Last edited on 2003-06-07 21:12:18 by stolfi
% modificado em 1o. de outubro de 2008
% modificado em 2012-09-25 para ajustar o pacote UTF8. Contribuicao de
%   Rogerio Cardoso

\documentclass[11pt,twoside]{article}
\usepackage{techrep-PFG-ic}

%%% SE USAR INGLÊS, TROQUE AS ATIVAÇÕES DOS DOIS COMANDOS A SEGUIR:
\usepackage[brazil]{babel}
%% \usepackage[english]{babel}

%%% SE USAR CODIFICAÇÃO LATIN1, TROQUE AS ATIVAÇÕES DOS DOIS COMANDOS A
%%% SEGUIR:
%% \usepackage[latin1]{inputenc}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}

\begin{document}

%%% PÁGINA DE CAPA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 
% Número do relatório
\TRNumber{01}

% DATA DE PUBLICAÇÃO (PARA A CAPA)
%
\TRYear{18}  % Dois dígitos apenas
\TRMonth{12} % Numérico, 01-12

% LISTA DE AUTORES PARA CAPA (sem afiliações).
\TRAuthor{G. L. da Silva \and E. Borin}

% TÍTULO PARA A CAPA (use \\ para forçar quebras de linha).
\TRTitle{Plataforma de processamento de dados sísmicos como serviço em Nuvem}

\TRMakeCover

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% O que segue é apenas uma sugestão - sinta-se à vontade para
% usar seu formato predileto, desde que as margens tenham pelo
% menos 25mm nos quatro lados, e o tamanho do fonte seja pelo menos
% 11pt. Certifique-se também de que o título e lista de autores
% estão reproduzidos na íntegra na página 1, a primeira depois da
% página de capa.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Nomes de autores ABREVIADOS e titulo ABREVIADO,
% para cabeçalhos em cada página.
%
\markboth{da Silva e Borin}{Processamento sísmico como serviço na nuvem}
\pagestyle{myheadings}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TÍTULO e NOMES DOS AUTORES, completos, para a página 1.
% Use "\\" para quebrar linhas, "\and" para separar autores.
%
\title{Plataforma de processamento de dados sísmicos como serviço em Nuvem}

\author{Guilherme Lucas da Silva \and Edson Borin}

\date{}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract} 
  Este trabalho é um relatório parcial de um projeto temático 
  plurianual, visando o estudo comparativo de diversas espécies de
  cervejas nativas do sub-continente brasileiro.  A realização deste
  trabalho contou com o suporte financeiro do CNPq e FAPESP, e foi
  imensamente facilitada pela infraestrutura de pesquisa cervisíaca
  instalada no Campus da UNICAMP.

  Com base nessas pesquisas, determinamos que a altura da cerveja $h$
  e a altura da espuma $e$ satifazem aproximadamente a inequação
  $(\sqrt{e^2 + h^2 + 2 h e})^3 \leq \exp(3 \log K_0^\ast)$, onde
  $K_0^\ast$ é a altura do copo.  Esta fórmula é válida,
  aparentemente, inclusive para espécies mais pigmentadas, como {\em
  Malzbier}.  Em vista disso, e dos resultados análogos obtidos por
  A. B. Stémio em experiências com {\em Guaraná} e $x$-{\em Cola},
  conjeturamos que a fórmula pode ser aplicada (com pequenas
  modificações) também a {\em Champagne} e outros líquidos de
  composição similar.
\end{abstract}

\section{Indsdas}

  As propriedades lúdicas, mnemolíticas e catalógicas de 
  soluções fraca- e medianamente concentradas de 1-metil-metanol
  em hidróxido de hidrônio aquoso ($\rm H_3O^{+} HO^{-}\cdot {\mathit n}H_2O$)
  tem sido objeto de intensos estudos experimentais por
  cientistas no mundo todo~\cite{AHU,KNU}.
  
  Durante os últimos 20 anos, os autores coordenaram uma equipe
  multidiplinar de pesquisadores, na UNICAMP e em outras instituições,
  cujo objetivo derradeiro é elucidar e\footnote{footnotes working fine} quantificar a relação entre...

\section{Introducão}

Computação em Nuvem é um conceito que está cada vez mais presente no cotidiano de todas as pessoas. Mesmo sem perceber, uma quantidade gigantesca de aplicações que usamos hoje 
em dia lançam mão desse conceito tão central para o desenvolvimento econômico e tecnológico de nossa sociedade contemporânea. Esse conceito se baseia na capacidade de usarmos o
poder computacional de uma infinidade de serviços como Máquinas virtuais, Bancos de Dados e Redes Virutais sem necessariamente possuirmos máquinas físicas com tais serviços 
instalados e configurados, ainda sendo possível, de maneira simples, expor tais serviços e mecanismos para vários usuários ao redor do mundo.
Entre as modalidades principais de serviços de computação em nuvem, temos três categorias mais relevantes:

\begin{itemize}

  \item \textbf{IaaS(Infrastructure as a Service):} essa é a maneira que dá mais responsabilidade ao usuário. Essa modalidade te dá máquinas virtualizadas que você deve gerenciar 
  instalação de programas, configurações e etc. Exemplo disso são máquinas virtuais que rodam sistemas operacionais GNU/Linux e são acessadas remotamente.
  \item \textbf{PaaS(Plataform as a Service):} Aqui, o usuário não precisa se preocupar com pacotes de sistema, softwares e configurações. Esse sabor de computação em nuvem, tenta 
  facilitar para desenvolvedores publicares suas aplicações. Isso siginifca que se, por exemplo, um usuário quiser publicar uma aplicação, não vai precisar se preocupar em
  instalar compiladores nem pacotes necessários para rodar a aplicação naquela determinada linguagem.
  \item \textbf{SaaS(Software as a Service):} essa é a modalidade que traz menos autonomia para o desenvolvedor, sendo que, através dela, todo o rescurso é gerenciado pelo provedor de 
  nuvem que é consumido. Alguns exemplos que podemos citar para ilustrar são bancos de dados como serviço, onde o usuário não se preocupa com nenhum tipo de infraestrutura, 
  somente usa o endereço que o provedor cede e faz uso das possibildiades de armazenamento que a plataforma oferece.

\end{itemize}

Entre as vantagens de se adotar um modelo de computação em nuvem ao invés de investir em realmente adiquirir máquinas físicas, podemos citar:

\begin{itemize}
  \item \textbf{Custo:} devido a possibilidade de pagar somente pelo o que está usando, ou seja, caso algum recurso está sendo pouco aproveitado, basta desligá-lo, usuários desse tipo de 
  plataforma não gastarão para manter sistemas parados.
  \item \textbf{Escalabilidade:} A computação em nuvem permite que, caso a aplicação preciso de muito mais poder computacional do que possui no momento, seja extremamente simples aumentar
  o número de instâncias ou o tamanho das máquinas, para atender mais usuários, gerando assim, mais receita.
  \item \textbf{Foco na aplicação:} desenvolvedores podem focar totalmente em escrever suas aplicações, sem a preocupação de gerenciar infraestutura e plataforma.

\end{itemize}

Entre os principais players de nuvem pública atualmente temos gigantes como Microsoft Azure(www.azure.com), Amazon Web Services(aws.com.br) e Google Cloud Plataform(gcp.com.br), 
oferecendo opções extremamente diversas para computação em nuvem, desde máquinas virtuais até mesmo bancos de dados gerenciados, onde a preocupação de gerenciamente fica totalmente
do lado do provedor do serviço.

Aplicações de HPC (High Processing Computing, computação de alto processamento, na tradução) são uma gama de programas que necessitam de muito poder computacional para 
completar as seus objetivos. Entre essas tarefas, estão o processamento de dados sísmicos, que são obtidas de maneira bruta e precisam de um trabalho muito pesado de tratamento
para que algumas conclusões possam ser feitas a partir dele. Ainda hoje, muitas dessas operações são feitas em servidores em institutos de pesquisas, por exemplo, podendo levar
a um custo excessivo, trabalho excessivo para gerenciamento de infraestrutura além de baixíssima agilidade e flexibilidade quanto a infraestrura. Assim, tais aplicações podem 
tirar muito proveito dos provedores de nuvem citados acima.

\section{Objetivos}
Esse trabalho tem como objetivo desenvolver uma plataforma Open Source(CITACAO) que torne extremamente simples para usuários que não conhecem conceitos de Computação em Nuvem rodarem suas aplicações.
A princípio, foram usadas aplicações para a prova de conceito. O desejado para o final da plataforma era que os usuários conseguissem processar os trabalhos sísmico sem nenhum conhecimento de Nuvem.  
Ao final, esperamos a criação de uma plataforma web, que tinha como principais funcionalidades:

\begin{itemize}
  \item \textbf{Submissão e gerenciamente de dados:} Essa funcionalidade é a responsável pelo upload de dados que serão usados nos processamentos, além de consultar quais dados foram submetidos, baixá-los e também
  excluí-los, caso necessário. 
  \item \textbf{Submissão e gerenciamento de binários:} esse componente do projeto é extremamente semelhante com a que detalhamos acima, porém, ao invés dos dados sísmicos, os artefatos que são gerenciados são os 
  binários das aplicações que serão utilizados nos processos.
  \item \textbf{Definição de tarefas sísmicas:} Utilizando os dados e binários submetidos a partir das duas funcionalidades citadas anteriormente, o objetivo era conseguir lançar um processamento que combina os dados e 
  binários, além dos argumentos necessários.
  \item \textbf{Obtenção dos resultados:} Ao final dos processos, é desejado que se consiga obter todos os resultados desse de maneira simples e rápida.
\end{itemize}

\section{Relevância}
Ao buscar por outras soluções que tem o mesmo intuito da plataforma que esse trabalho tem por objetivo desenvolver, notamos a sua extrema relevância, uma que vez que é extremamente difícil achar outros softwares
open source que executam tal tarefa.
Além da unicidade que o trabalho possui no cenários atual, ele se torna relevante já que ele pode abstrair os novos conceitos e a curva de aprendizado que vem junto com a computação em nuvem. Assim é possível
tirar proveito de todos os benefícios que foram citados acima, levando a possibilidade de um uso muito mais inteligente dos recursos, baixando custos e aumentando a produtividade.

\section{Procedimento}
Para o sucesso final do projeto, ao começo dele, foi decidido que faríamos uma plataforma web. Essa fi a decisão devido a facilidade de desenvolver para esse tipo de plataforma, além do alcance
gigantesco que plataformas web possuem, já que é praticamente obrigatório nos dispositivos que os usuários poderiam usar para acessar o sistema (smartphones e computadores) possuir um
navegador de internet instalado. Além disso, vale ressaltar que desde o início do projeto todo o código estava totalmente aberto no Github, já que foi uma premissa desde o início do projeto que este
seria Open Source.

Ao iniciar a análise do problema, foi possível notar que uma arquitetura de nuvem que se encaixa muito bem nesse problema é a de Work Queues(Filas de Trabalho), que segundo Brendan Burns em seu livro
Designing Distributed Systems, "Em um sistema de filas de trabalho existe uma trabalho em batch para ser executado. Cada parte do trabalho é independente do outro e pode ser executado sem nenhuma interaçao".
Isso é exatamente o que foi buscado, uma vez que os trabalhos eram intensivos, demoravam um tempo para serem reproduzidos e eram independentes um do outro. Assim, o que gostaríamos era que trabalhos fossem submetidos
a uma fila e, alguma unidade de computação o usasse para executar uma definição de trabalho.

\begin{figure}[!h]
  \centering
  \includegraphics[scale=0.4]{arch.eps}
  \caption{Arquitetura inicial do projeto e exemplo de filas da trabalho distribuídas}
  \label{fig:archtec}
\end{figure}

A imagem ~\ref{fig:archtec} ajuda a explicar como é o funcionamento dessa arquitetura e a arquitetura inicial do projeto.

Então, a plataforma foi separada em duas grandes partes:

\begin{itemize}
  \item \textbf{Front-End:} A parte que o usuário realmente vê, o código que irá rodar no navegador do seu dispositivo. (Colocar alguma sitação)
  \item \textbf{Back-End:} Essa é a porção da plataforma responsável por características que são invisíveis ao usuário. Entre elas, podemos citar acesso ao banco de dados, autenticação, processamento de dados,
  submissão de dados para a nuvem, etc.
\end{itemize}

Existem alguns componentes que foram usados em comum entre essas duas partes:

\begin{itemize}
  \item \textbf{Docker(Link):} uma maneira muito simples de empacotar as aplicações, isolando dependências, garantindo que o deploy sempre é feito da maneira correta. Assim, é possível entregar as aplicações completas, com
  todos os requisitos necessários instalados, o que da uma agilidade enorme durante o ciclo de desenvolvimento.
  \item \textbf{Nginx(Link):} Servidor web open source extremamente escalável e fácil de configurar. Foi usado tanto para servir o back end quando o front end. A outra opção para esse trabalho seria o Apache Web Server, porém
  o Nginx se mostrou mais simples e rápido de ter aplicações rodando.
\end{itemize}

\subsection{Front End}

Para o desenvolvimento do front end, foram definidas de antemão como seria a composição geral das telas e como seria o fluxo da aplicação. Assim, foi decidido que o layout geral das telas, seriam:

\begin{figure}[!h]
  \centering
  \includegraphics[scale=0.4]{login.eps}
  \caption{Página de Login}
  \label{fig:loginScreen}
\end{figure}

A figura ~\ref{fig:loginScreen} mostra como definimos quais informações deveriam estar na tela para que o usuário pudesse se conectar a plataforma. Como mostrado, 
as informações necessárias para logar no sistema eram email e senha que foram previamente cadastrado.

\begin{figure}[!h]
  \centering
  \includegraphics[scale=0.4]{account_reg.eps}
  \caption{Página de criaçao de conta}
  \label{fig:createScreen}
\end{figure}

A figura ~\ref{fig:createScreen} deixa claro quais foram as informações que eram requeridas para se criar uma conta no sistema. 

\begin{figure}[!h]
  \centering
  \includegraphics[scale=0.2]{First_screen.eps}
  \caption{Página de definição dos trabalhos}
  \label{fig:definitionScreen}
\end{figure}


A figura ~\ref{fig:definitionScreen} exemplifica como imaginamos a tela de definicao de um trabalho para ser executado. Nesse primeiro protótipo, foi pensado que somente 
as informações mostradas na tela, eram o suficente.

\begin{figure}[!h]
  \centering
  \includegraphics[scale=0.2]{Second_screen.eps}
  \caption{Página de observação do status}
  \label{fig:statusScreen}
\end{figure}


O protótipo da tela de status dos trabalhos está mostrada na figura ~\ref{fig:statusScreen}. Extremamente simples a princípio, uma tabela mostrando o status de cada trabalho. 

\begin{figure}[!h]
  \centering
  \includegraphics[scale=0.2]{Third_screen.eps}
  \caption{Página de obtenção dos resultados}
  \label{fig:resultsScreen}
\end{figure}

A ultima figura ~\ref{fig:resultScreen} mostra como foi pensada a obtenção dos resultados.

\begin{figure}[!h]
  \centering
  \includegraphics[scale=0.2]{tcc_flow.eps}
  \caption{Fluxo entre os componentes da plataforma}
  \label{fig:flowScreen}
\end{figure}

Vale ressaltar que essa ideia inicial foi considerada com poucas das funcionalidades que realmente eram relevantes para a plataforma. Assim, o fluxo de todo o trabalho foi 
repensado para algo mais próximo do representado na figura ~\ref{fig:flowScreen}. Nesse fluxo definido, os quadrados representam as telas, com suas respectivas interações com 
as camadas de armazenamento que são necessárias para completar suas tarefas com sucesso. Assim, entrando no detalhe de cada componente da solução:

\begin{itemize}
  \item \textbf{Data Management:} Componente responsável pelo gerencimento dos dados sísmicos da plataforma. A intenção nesse componente é ser capaz de adicionar, remover e 
  movê-los de um tipo de armazenamento mais caro (porém mais rápido) para um mais barato, ligeiramente mais lento. 
  \item \textbf{Flow Management:} Componente responsável por determinar uma sequencia de passos que devem ser feitas para completar uma tarefa. Diferente dos trabalhos (Tasks),
  aqui a definição é de um conjunto de tasks, encadeadas para obter um resultado maior.
  \item \textbf{Tools Management:} Essa funcionalidade procura realizar o gerenciamento dos binários que serão executados. Assim como o componente respoonsável pelo gerenciamento
  dos dados, esse componente busca dar a possibilidade de adicionar, mover e excluir binários da plataforma.
  \item \textbf{Running Tasks:} Nessa tela, é desejado que o usuário consiga ver qual é o status dos processamentos que iniciou. Status como Pendente e Pronto são alguns dos 
  possíveis.
  \item \textbf{New Tasks:} Responsável por definir novas tarefas a serem rodadas. É desejado que as características necessárias para essa definição sejam binário, dado sísmico 
  e argumentos para a execução acontecer com sucesso. 
  \item \textbf{Results:} Os resultados dos processamentos executados estarão aqui, organizados pela execução que o gerou.
\end{itemize}

Como tecnologias para o desenvolvimento da nossa plataforma, especificamente para o front end, foram escolhidas as seguintes tecnologias:

\begin{itemize}
  \item \textbf{Angular(LINK):} Framework(link abaixo) para desenvolvimento de aplicações web Open Source, desenvolvido inicialmente pelo Google e agora também mantido pela comunidade. Usa como linguagem de desenvolvimento o
  Typescript(LINK). A escolha desse framework aconteceu uma vez que ela é extremamente produtiva e por ser um framework completo, já encapsulando todo o conceito de serviços, estilo de página e 
  linguagem de marcação, roteamento. Assim, com esse framework ainda é necessário conhecer linguagens de marcação como HTML (link) e CSS (link), mas a junção de todos esses conceitos fica muito mais simples.
  \item \textbf{Bootstrap(LINK):} Frameworks que possui o estilo de vários componentes web prontos, como tabelas, menu laterais, barras superiores, etc. É o que muitos sites usam hoje em dia, como é o caso do github(LINK)
  Estilizar páginas web pode ser um trabalho extremamente complicado e demorado, por isso optamos por usar um framework. Existem outros frameworks CSS interessantes, porém poucos tem a maturidade do bootstrap.
\end{itemize}

Foi garantido que o deploy fosse feito da maneira mais simples e flexível para o cliente. Então, foi usado o servidor web nginx(site) para isso. Aém disso, também foi disponibilizado um Dockerfile, que possibilita
o deploy da solução de maneira extremamente simples e direta sobre Containers Docker.

\subsection{Back End}

Ao início do desenvolvimento do back end, buscamos definir quais seriam as melhores tecnologias para esse componente, além de definir como seriam as rotas e contratos que a API (link) do back end iria expor
para que o front end pudesse consumir de forma eficaz e direta, garantindo assim, um total desacoplamento entre os dois componentes. Assim, os componentes que decidimos para o back end foram os seguintes:

\begin{itemize}
  \item \textbf{Python(link):} Linguagem criada por Guido Van Rossum, extremamente relevante nos dias de hoje devido a sua enorme gama de aplicações, que vão desde embarcados até sistemas de análise de dados de alto 
  desempenho. A escolha dela foi devido principalmente a bibliotecas muito maduras para desenvolvimento de API's back end, filas de trabalho distribuídas e conectores com bancos de dados.

  \item \textbf{Flask(link):} Framework para desenvolvimento de APIS para Python. Foi escolhido devido a extrema agilidade para colocar uma API rodando. Além disso, é muito simples entender como a aplicação está funcionando,
  fator muito crítico para decidirmos na escolha desta, uma vez que o projeto tem como premissa ser Open Source e facilitar o entendimento de todos que o usam. Ao invés de Python/Flask, foram cogitadas também ASP .NET
  com C\# e NodeJS. A primeira foi descartada devido a complexidade para simplesmente criarmos uma API. NodeJS não foi escolhido devido a dificuldade que novos programadores podem enfrentar para compreender as
  fucnionalidades em um primeiro momento, quando fossem aumentar o projeto.

  \item \textbf{Celery(link):} Uma vez escolhido Python e Flask como ferramentas para o desenvolvimento da solução, foi muito natural a escolha do Celery como ferramenta para trabalhar com filas de trabalho. Existem muitos
  casos de sucesso espalhados pela internet de engenheiros e desenvolvedores que usaram essa combinação com total eficácia. O Celery é um componente do Python que é o responsável por gerenciar, submeter e obter
  resultados de uma fila de trabalho, de uma maneira muito simples. Além disso, dá suporte a vários componentes de mensageria, como por exemplo, RabbitMQ(link), Redis(link), Amazon SQS(link).

  \item \textbf{Redis(link):} Após a escolha de qual biblioteca iríamos usar para facilitar a tarefa de filas de trabalho, que foi o Celery, foi preciso escolher algum componente para a mensageria do projeto, ou seja, o
  componente que realmente é responsável por armazenar e distribuir as mensagens relacionadas aos trabalhos submetidos na solução. Entre as opções estavam RabbitMQ, Redis e Amazon SQS. Essas as que melhor se 
  integravam com o celery, sendo possível obter todas as suas funcionalidades com qualquer um desses três. Porém, Amazon SQS é uma opção presa a um provedor de nuvem, o que complica o andar do projeto, caso seja 
  preciso usar outra cloud diferente da AWS. RabbitMQ e Redis ofereciam funcionalidades muito parecidas, porém o Redis foi escolhido, devido a infinidade de materiais sobre o uso dele e suas outras funcionalidades
  que podem ser tiradas proveito também, como, por exemplo, cache e armazenamento de dados em memória.

  \item \textbf{MongoDB(link):} Para o armazenamento dos dados de cadastro de usuários, informações sobre argumentos de cada tipo de binário e etc, a escolha foi um banco de dados NoSQL(referencia), o MongoDB. A escolha deste
  foi muito direta, uma vez que os dados que estavam trafegando entre um serviço e outro tinham uma estrutura muito parecida com os documentos que são guardados nesse tipo de banco, não sendo necessário de preocupar
  em transformar os dados para os esquemas presentes em tabelas SQL(referencia), o que agiliza muito o trabalho.

  \item \textbf{Blob Storage(link):} o Blob Storage do Microsoft Azure foi a opção aqui pois era necessário uma espécie de armazenamento de propósito geral. Aqui ele está sendo usado para armazenamento dos dados sísmicos e
  binários. Foi escolhido devido a excelente integração que possui com Python. Outras opções existentes eram, por exemplo, Amazon S3(link), que oferece serviços muito parecidos. Outra opção era deixar esses dados em 
  no disco de máquinas virtuais e serví-los por meio de servidores, porém, isso aumentaria muito a complexidade e dificultaria a tarefa de gerenciar esse tipo de infraestrutura.
\end{itemize}

\subsection{Ferramentas para Deploy}

Como dito anteriormente, ao iniciar o projeto, não era desejado que estivéssemos presos a um modelo específico de deployment. Assim, para facilitar o deploy da aplicação independente
do modo que foi escolhido para o deploy, foi criado uma série de scripts em ferramentas específicas para ajudar. Existem dois modelos que estão sendo facilitados:

\begin{itemize}
  \item \textbf{Kubernetes(link):} Orquestrador de Containers extremamente famoso nos dias de hoje, que tem como principal funcionalidade tornar mais simples, escalável e performática o deploy 
  de aplicações baseadas em Containers. Nascida dentro do Google, a partir do Borg (paper) atualmente está sob a jurisdição da Cloud Native Foundation(link) e é Open Source. Foi uma
  das plataformas que foi visada por ter apresentado extremamente relevancia nos ultimos tempos, com todos os grandes provedores de Nuvem oferecendo opções gerenciadas dessa 
  ferramenta.
  \item \textbf{Ansible(link):} um modelo muito comum de deploy de aplicações é baseada em máquinas virtuais. Nesse caso, é bom garantir que todas as dependências necessárias para que a 
  aplicação rode com sucesso estejam instaladas. Nesse aspecto, o Ansible se mostra extremamente eficaz. Essa ferramenta surgiu da Red Hat e também é mantida Open Souce, sendo um
  ótimo gerenciador de configurações, que torna possível escrever configurações como código, o que garante que a aplicação sempre terá sucesso para ser executada.
\end{itemize}

\subsection{Resultados}

Após seguir todo o experimento citado acima, foi alcançado um resultado muito próximo do esperado. A arquitetura final do projeto, está mostrada na figura (linkar a figura).

\begin{figure}[!h]
  \centering
  \includegraphics[scale=0.2]{final_arch.eps}
  \caption{Arquitetura final do projeto}
  \label{fig:finalArch}
\end{figure}

Dada a arquitetura final do projeto mostra na figura ~\ref{fig:finalArch} os componentes mostrados tem, cada um, a seguinte função:

\begin{itemize}
  \item \textbf{Web Client:} componete que roda no lado do cliente. Seguimos com o que foi proposto no início do projeto e explicado durante o procedimento, ou seja, todo o código do lado do cliente 
  foi escrito em Typescript, com o auxílio do framework Angular, a estilização das páginas foi feita com Bootstrap e servido via Nginx.
  \item \textbf{Flask Back End:} responsável por receber todas as requisições que saem do front end. Funciona como um gateway(talvez uma citação). Também foi seguido o plano inicial de escrever todo o back end com
  Python, Flask e Celery. Esse é o componente que possui mais responsabilidades: autenticação, comunicação com a fila com o auxílio do Celery, acesso aos Blobs e acesso ao banco.
  \item \textbf{Linux Workers:} Componentes que são responsável pela execução propriamente dita dos pedidos. Com o auxílio do Celery, esperam por pedidos entrarem na fila, e assim que isso acontece, executam. 
  É possível ter um cluster de máquinas com esse papel, aumentando o paralelismo das execuções.
  \item \textbf{Message queue with Redis:} também parte do plano inicial, a fila de mensagens com o Redis foi a maneira mais eficaz e resiliente que encontramaos de desacoplar o back end dos Linux workers. Assim
  O back end somente precisava submeter uma mensagem com as definições para a execução de um trabalho na fila e algum worker pegaria essa requisição e faria o processamento necessário. Aqui vale um observação 
  importante. A escolha do Celery e do modelo de filas de trabalhos distribuídas, que já foi explicada anteriormente, torna possível, além de desacoplar o back end dos workers, ainda torna possível a execução de
  processamentos em paralelo e distribuídos, não criando um gargalo na solução, possivelmente ocasionado pelo grande número de pedidos na fila esperando por um único worker.
  
  \begin{figure}[!h]
    \centering
    \includegraphics[scale=1.0]{tools_model.eps}
    \caption{Modelo presente na coleção de ferramentas binárias}
    \label{fig:toolsCollection}
  \end{figure}

  \item \textbf{toolsCollection:} coleção dentro do banco que guarda informações sobre os binários que estão armazenados. Novos dados são inseridos nela quando submetidos um novo binário é armazenado, quando
  um novo pedido de processamento será incluído, já que é necessário consultar quais os parâmetros para esse e também quando um binário é excluido, apagando o registro.
  O modelo que está sendo usado para guardar essas informações é o que esta na ~\ref{fig:toolsCollection}
  
  \begin{figure}[!h]
    \centering
    \includegraphics[scale=1.0]{results.eps}
    \caption{Modelo presente na coleção de resultados}
    \label{fig:resultsCollection}
  \end{figure}

  \item \textbf{resultsColleciton:} coleção de documentos no banco para guardar os dados do resultado, armazena o id do processamento, dado e binário usado, além dos argumentos. 
  Essa coleção é acessada após o término de cada processamento, para salvar as informações do resultado e também quando é desejado que todos os resultados sejam mostrados na tela de gerenciamento
  de resultados. O modelo segue o padrão da ~\ref{fig:resultsCollection}.

  \begin{figure}[!h]
    \centering
    \includegraphics[scale=1.0]{users_model.eps}
    \caption{Modelo presente da coleçao de usuários}
    \label{fig:usersCollection}
  \end{figure}

  \item \textbf{usersCollection:} usada para armazenamento de dados dos usuários, como senha e email para autenticação. Um novo registro é criado nessa coleção quando um usuário cria uma nova conta. 
  A coleção também é acessada para autenticação de um novo usuário. Para que todos esses processos sejam executados com sucesso, o modelo usado é o da ~\ref{fig:usersCollection}.

  \item \textbf{seismic-tools:} Blob usado para armazenar os binários submetidos pelos usuário. Acessado pelo componemte de gerenciamento de ferramentas quando uma nova ferramente é inserida na plataforma 
  e quando o processamento vai acontecer, pois nesse momento é necessário baixar esses dados para execução em um dos workers.
  \item \textbf{seismic-data:} Blob que armazena os dados sísmicos submetidos. Também são acessados pelo componente de gerenciamento de dados quando um novo dado é incluido, excluído e na execução dos 
  trabalhos, já que é necessário baixar esses dados.
  \item \textbf{seismic-results:} Outro blob. Esse, responsável por armazenar os resultados dos processamentos. Todos os resultados são empacotados em um arquivo tar.gz(link) e disponibilizados para download, 
  no componente responsável por gerenciar os resultados.
\end{itemize}

Vale notar aqui que, usamos somente uma instância de bancos de dados, com coleções diferentes para cada tipo de aplicação, as Collections, no caso. Também usamos a mesma estratégia para o blob. Foi usada somente 
uma conta de armazenamento no Microsoft Azure, com pastas separadas para cada uso, que no caso, são seismic-data, seismic-tools e seismic-results. 

\begin{thebibliography}{99}

\bibitem{AHU} A. V. Aho, J. E. Hopcroft and J.  D.  Ullman, {\it The
Design and Analysis of Computer Algorithms,} Addison-Wesley (1901).

\bibitem{KNU} D. E. Knuth and L. Lamport, {\it A structural analysis
of the role of gnus and gnats in the post-modernistic, crypto-existential 
Weltanschauung of neo-liberal Tibeto-Vietnamese leaf blower operators 
as manifest in the sexual symbology of the Los Angeles Phone Directory}.
Journal of Gnu Technology, {\bf 23} (6), 12--87
(March 1996).

\end{thebibliography}

\end{document}
